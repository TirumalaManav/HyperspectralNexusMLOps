# ğŸ›°ï¸ Hyperspectral Image Classification Framework

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Flask](https://img.shields.io/badge/Flask-Web%20Framework-green.svg)](https://flask.palletsprojects.com/)
[![Research](https://img.shields.io/badge/Research-In%20Progress-orange.svg)](https://github.com/TirumalaManav/Hyperspectral-Image-Classification-Framework)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ¯ Abstract

The **Hyperspectral Image Classification Framework** is an advanced deep learning platform designed for precision classification of hyperspectral imagery using multiple neural network architectures. This framework implements three distinct approaches: **Convolutional Neural Networks (CNN)**, **Convolutional Autoencoders (CAE)**, and **Generative Adversarial Networks (GAN)** for comprehensive hyperspectral data analysis.

The system incorporates secure user authentication with cryptographic face verification, comprehensive dataset support, and a production-ready web interface for real-time classification and model training.

## ğŸš€ Key Features

### **ğŸ” Security & Authentication**
- **Cryptographic Face Verification**: Secure user registration and login
- **Encrypted Data Storage**: .bin files with cryptographic protection
- **Secure Reference System**: Protected storage of biometric templates

### **ğŸ§  Multiple Architectures**
- **HICNN**: Custom CNN with 3/5/7 layer variants
- **HICAE**: Convolutional Autoencoder for feature learning
- **HIC-GAN**: Generative Adversarial Network for data augmentation

### **ğŸ“Š Comprehensive Dataset Support**
- **Indian Pines**: Agricultural hyperspectral dataset
- **Pavia University/Centre**: Urban hyperspectral imagery
- **Botswana**: Wetland classification dataset
- **Salinas**: Agricultural scene classification
- **KSC**: Kennedy Space Center hyperspectral data

### **ğŸ¯ Advanced Optimization**
- **Multiple Optimizers**: Adam, SGD, Adadelta, Adagrad
- **Adaptive Learning**: Dynamic learning rate adjustment
- **Batch Normalization**: Improved training stability
- **Dropout Regularization**: Overfitting prevention


## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HYPERSPECTRAL CLASSIFICATION FRAMEWORK       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   WEB INTERFACE â”‚  â”‚  AUTHENTICATION â”‚  â”‚   DATA STORAGE  â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚
â”‚  â”‚  â€¢ Flask App    â”‚  â”‚  â€¢ Face Verify  â”‚  â”‚  â€¢ Datasets     â”‚  â”‚
â”‚  â”‚  â€¢ Templates    â”‚  â”‚  â€¢ Cryptography â”‚  â”‚  â€¢ Models       â”‚  â”‚
â”‚  â”‚  â€¢ Static Files â”‚  â”‚  â€¢ Secure Login â”‚  â”‚  â€¢ Results      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        PROCESSING PIPELINE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   DATA INPUT    â”‚  â”‚   PREPROCESSING â”‚  â”‚    TRAINING     â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚
â”‚  â”‚  â€¢ Image Upload â”‚  â”‚  â€¢ Normalizationâ”‚  â”‚  â€¢ Model Select â”‚  â”‚
â”‚  â”‚  â€¢ Dataset Load â”‚  â”‚  â€¢ Patch Extractâ”‚  â”‚  â€¢ Hyperparams  â”‚  â”‚
â”‚  â”‚  â€¢ Format Check â”‚  â”‚  â€¢ Augmentation â”‚  â”‚  â€¢ Optimization â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      NEURAL ARCHITECTURES                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     HICNN       â”‚  â”‚     HICAE       â”‚  â”‚     HIC-GAN     â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚
â”‚  â”‚  â€¢ Conv Layers  â”‚  â”‚  â€¢ Encoder-Dec  â”‚  â”‚  â€¢ Generator    â”‚  â”‚
â”‚  â”‚  â€¢ Batch Norm   â”‚  â”‚  â€¢ Feature Ext  â”‚  â”‚  â€¢ Discriminatorâ”‚  â”‚
â”‚  â”‚  â€¢ Max Pooling  â”‚  â”‚  â€¢ Reconstructionâ”‚  â”‚  â€¢ Classifier   â”‚  â”‚
â”‚  â”‚  â€¢ 3/5/7 Depths â”‚  â”‚  â€¢ Classificationâ”‚  â”‚  â€¢ Adversarial  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        OUTPUT & ANALYSIS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   PREDICTIONS   â”‚  â”‚   VISUALIZATION â”‚  â”‚     RESULTS     â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚
â”‚  â”‚  â€¢ Class Labels â”‚  â”‚  â€¢ Confusion Matâ”‚  â”‚  â€¢ Accuracy     â”‚  â”‚
â”‚  â”‚  â€¢ Confidence   â”‚  â”‚  â€¢ Loss Curves  â”‚  â”‚  â€¢ Precision    â”‚  â”‚
â”‚  â”‚  â€¢ Probability  â”‚  â”‚  â€¢ Feature Maps â”‚  â”‚  â€¢ Recall       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”¬ Architecture Diagrams

### **1. HICNN (Hyperspectral CNN) Architecture**

```
Input: [Batch, 103, 7, 7] (Hyperspectral Patches)
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       HICNN ARCHITECTURE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input Layer (103 bands, 7Ã—7 patches)                          â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Conv2D(103â†’64) + BatchNorm + ReLU + MaxPool(2Ã—1)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Conv2D(64â†’128) + BatchNorm + ReLU + MaxPool(2Ã—1)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Conv2D(128â†’256) + BatchNorm + ReLU + MaxPool(2Ã—1)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Conv2D(256â†’512) + BatchNorm + ReLU + MaxPool(2Ã—1)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Conv2D(512â†’1024) + BatchNorm + ReLU + MaxPool(2Ã—1)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Flatten â†’ FC(1024Ã—2Ã—2 â†’ 1024) â†’ ReLU                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ FC(1024 â†’ n_classes) â†’ Softmax                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
           Output: [Batch, n_classes] (Classification)
```

### **2. HICAE (Hyperspectral Convolutional Autoencoder) Architecture**

```
Input: [Batch, 103, 7, 7] (Hyperspectral Patches)
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      HICAE ARCHITECTURE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        ENCODER BRANCH                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Conv2D(103â†’64) + BatchNorm + ReLU + MaxPool(2Ã—2)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Conv2D(64â†’128) + BatchNorm + ReLU + MaxPool(2Ã—2)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Conv2D(128â†’256) + BatchNorm + ReLU (Encoded Features)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚              â–¼                         â–¼                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚   DECODER BRANCH    â”‚   â”‚     CLASSIFIER BRANCH       â”‚   â”‚
â”‚    â”‚                     â”‚   â”‚                             â”‚   â”‚
â”‚    â”‚ ConvTranspose2D     â”‚   â”‚ Conv2D(256â†’512)             â”‚   â”‚
â”‚    â”‚ (256â†’128) + BN+ReLU â”‚   â”‚ + BatchNorm + ReLU          â”‚   â”‚
â”‚    â”‚         â”‚           â”‚   â”‚         â”‚                   â”‚   â”‚
â”‚    â”‚         â–¼           â”‚   â”‚         â–¼                   â”‚   â”‚
â”‚    â”‚ ConvTranspose2D     â”‚   â”‚ Conv2D(512â†’1024)            â”‚   â”‚
â”‚    â”‚ (128â†’64) + BN+ReLU  â”‚   â”‚ + BatchNorm + ReLU          â”‚   â”‚
â”‚    â”‚         â”‚           â”‚   â”‚         â”‚                   â”‚   â”‚
â”‚    â”‚         â–¼           â”‚   â”‚         â–¼                   â”‚   â”‚
â”‚    â”‚ ConvTranspose2D     â”‚   â”‚ AdaptiveAvgPool2d(2Ã—2)      â”‚   â”‚
â”‚    â”‚ (64â†’103) + Sigmoid  â”‚   â”‚         â”‚                   â”‚   â”‚
â”‚    â”‚         â”‚           â”‚   â”‚         â–¼                   â”‚   â”‚
â”‚    â”‚         â–¼           â”‚   â”‚ Flatten â†’ FC(4096â†’1024)     â”‚   â”‚
â”‚    â”‚ Reconstructed       â”‚   â”‚         â”‚                   â”‚   â”‚
â”‚    â”‚ Output              â”‚   â”‚         â–¼                   â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ FC(1024â†’n_classes)          â”‚   â”‚
â”‚                              â”‚         â”‚                   â”‚   â”‚
â”‚                              â”‚         â–¼                   â”‚   â”‚
â”‚                              â”‚ Classification Output       â”‚   â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **3. HIC-GAN (Hyperspectral GAN) Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        HIC-GAN ARCHITECTURE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Noise Vector (z_dim) + Class Labels (c_dim)                   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    GENERATOR                            â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Linear(z_dim+c_dim â†’ h_dim) + SELU                    â”‚   â”‚
â”‚  â”‚                    â”‚                                    â”‚   â”‚
â”‚  â”‚                    â–¼                                    â”‚   â”‚
â”‚  â”‚  Linear(h_dim â†’ h_dim) + SELU (Ã—7 layers)              â”‚   â”‚
â”‚  â”‚                    â”‚                                    â”‚   â”‚
â”‚  â”‚                    â–¼                                    â”‚   â”‚
â”‚  â”‚  Linear(h_dim â†’ X_dim) + Sigmoid                       â”‚   â”‚
â”‚  â”‚                    â”‚                                    â”‚   â”‚
â”‚  â”‚                    â–¼                                    â”‚   â”‚
â”‚  â”‚              Generated Samples                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚           â–¼               â–¼               â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  DISCRIMINATOR  â”‚ â”‚   CLASSIFIER    â”‚ â”‚  REAL SAMPLES   â”‚   â”‚
â”‚  â”‚                 â”‚ â”‚                 â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚ Linear(X_dim    â”‚ â”‚ Linear(X_dim    â”‚ â”‚ Ground Truth    â”‚   â”‚
â”‚  â”‚ â†’ h_dim) + ELU  â”‚ â”‚ â†’ h_dim) + ELU  â”‚ â”‚ Hyperspectral   â”‚   â”‚
â”‚  â”‚       â”‚         â”‚ â”‚       â”‚         â”‚ â”‚ Data            â”‚   â”‚
â”‚  â”‚       â–¼         â”‚ â”‚       â–¼         â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚ Linear Layers   â”‚ â”‚ Linear Layers   â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚ (Ã—9) + ELU      â”‚ â”‚ (Ã—9) + ELU      â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚       â”‚         â”‚ â”‚ + Dropout       â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚       â–¼         â”‚ â”‚ + BatchNorm     â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚ Linear(h_dim    â”‚ â”‚       â”‚         â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚ â†’ 1) [Real/Fake]â”‚ â”‚       â–¼         â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚                 â”‚ â”‚ Linear(h_dim    â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚                 â”‚ â”‚ â†’ c_dim)        â”‚ â”‚                 â”‚   â”‚
â”‚  â”‚                 â”‚ â”‚ [Classification]â”‚ â”‚                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                TRAINING OBJECTIVES                      â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  â€¢ Adversarial Loss: min_G max_D V(D,G)                â”‚   â”‚
â”‚  â”‚  â€¢ Classification Loss: CrossEntropy(C(x), y)          â”‚   â”‚
â”‚  â”‚  â€¢ Feature Matching: ||E[f(x)] - E[f(G(z))]||Â²        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


## ğŸ“ Project Structure

```
Hyperspectral-Image-Classification-Framework/
â”œâ”€â”€ ğŸ“ captured_images/                    # Login face verification images
â”œâ”€â”€ ğŸ“ secure_data/
â”‚   â”œâ”€â”€ ğŸ“ reference_images/               # Registration face images
â”‚   â””â”€â”€ ğŸ“ *.bin                          # Encrypted biometric data
â”œâ”€â”€ ğŸ“ Datasets/
â”‚   â”œâ”€â”€ ğŸ“ IndianPines/
â”‚   â”‚   â”œâ”€â”€ Indian_pines_corrected.mat    # Hyperspectral data
â”‚   â”‚   â””â”€â”€ Indian_pines_gt.mat           # Ground truth labels
â”‚   â””â”€â”€ ğŸ“ PaviaU/
â”‚       â”œâ”€â”€ PaviaU.mat                    # Pavia University dataset
â”‚       â””â”€â”€ PaviaU_gt.mat                 # Pavia ground truth
â”œâ”€â”€ ğŸ“ HIC Images/                        # Training results by architecture
â”‚   â”œâ”€â”€ ğŸ“ HICNN 3 Adam/                  # CNN 3-layer with Adam optimizer
â”‚   â”œâ”€â”€ ğŸ“ HICNN 3 SGD/                   # CNN 3-layer with SGD optimizer
â”‚   â”œâ”€â”€ ğŸ“ HICNN 5 Adadelta/              # CNN 5-layer with Adadelta
â”‚   â”œâ”€â”€ ğŸ“ HICNN 7 Adagrad/               # CNN 7-layer with Adagrad
â”‚   â””â”€â”€ ...                               # All combinations (3Ã—4 optimizers)
â”œâ”€â”€ ğŸ“ results/
â”‚   â””â”€â”€ ğŸ“ training_YYYYMMDD_HHMMSS/      # Timestamped training results
â”‚       â””â”€â”€ ğŸ“ visualizations/            # Classification reports & graphs
â”œâ”€â”€ ğŸ“ GAN/                               # GAN architecture implementation
â”‚   â”œâ”€â”€ ğŸ“ Datasets/                      # Multiple hyperspectral datasets
â”‚   â”‚   â”œâ”€â”€ ğŸ“ Botswana/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ KSC/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ Salinas/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ğŸ“ GAN Excel/                     # Performance metrics
â”‚   â”‚   â”œâ”€â”€ Classifier Score.xlsx
â”‚   â”‚   â”œâ”€â”€ Fake Image Score.xlsx
â”‚   â”‚   â””â”€â”€ GAN Scores CRI.xlsx
â”‚   â”œâ”€â”€ ğŸ“ Gan Results/                   # Results by dataset
â”‚   â”‚   â”œâ”€â”€ ğŸ“ Botswana Dataset/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ India Pines Dataset/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ğŸ“Š GAN Botswana.ipynb             # GAN training notebooks
â”‚   â”œâ”€â”€ ğŸ“Š GAN IndianPines.ipynb
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“ HIC-CLI/                           # Command Line Interface version
â”‚   â”œâ”€â”€ ğŸ“ .ipynb_checkpoints/            # Jupyter notebook checkpoints
â”‚   â”œâ”€â”€ ğŸ“ checkpoints/                   # Model checkpoints
â”‚   â”œâ”€â”€ ğŸ“ Datasets/                      # CLI datasets
â”‚   â”œâ”€â”€ ğŸ“Š Clear GPU Memory.ipynb         # GPU memory management
â”‚   â”œâ”€â”€ ğŸ custom_datasets.py             # Custom dataset implementations
â”‚   â”œâ”€â”€ ğŸ datasets.py                    # Dataset loading utilities
â”‚   â”œâ”€â”€ ğŸ inference.py                   # Model inference script
â”‚   â”œâ”€â”€ ğŸ main.py                        # Main CLI script
â”‚   â”œâ”€â”€ ğŸ models.py                      # Model architectures
â”‚   â”œâ”€â”€ ğŸ utils.py                       # Utility functions
â”‚   â””â”€â”€ ğŸ“„ requirements.txt               # CLI dependencies
â”œâ”€â”€ ğŸ“ static/                            # Web interface static files
â”œâ”€â”€ ğŸ“ templates/                         # HTML templates
â”‚   â”œâ”€â”€ ğŸ“„ home.html                      # Main dashboard
â”‚   â”œâ”€â”€ ğŸ“„ train.html                     # Model training interface
â”‚   â”œâ”€â”€ ğŸ“„ prediction.html                # Classification interface
â”‚   â”œâ”€â”€ ğŸ“„ register.html                  # User registration
â”‚   â”œâ”€â”€ ğŸ“„ about.html                     # Project information
â”‚   â””â”€â”€ ğŸ“„ contact.html                   # Contact page
â”œâ”€â”€ ğŸ app.py                             # Main Flask application
â”œâ”€â”€ ğŸ face_verification.py               # Cryptographic authentication
â”œâ”€â”€ ğŸ mlpipeline.py                      # ML training pipeline
â”œâ”€â”€ ğŸ prediction.py                      # Prediction pipeline
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                          # Project documentation
â”œâ”€â”€ ğŸ“„ LICENSE                            # MIT License
â”œâ”€â”€ ğŸ“„ AUTHORS                            # Contributors
â””â”€â”€ ğŸ“„ .gitignore                         # Git ignore rules
```

## ğŸš€ Quick Start

### **Prerequisites**
```bash
# Python 3.8+ required
python --version

# Install CUDA for GPU acceleration (optional but recommended)
nvidia-smi  # Check GPU availability
```

### **Installation**
```bash
# Clone the repository
git clone https://github.com/TirumalaManav/HyperspectralNexusMLOps
cd HyperspectralNexusMLOps

# Create virtual environment
python -m venv hic_env
source hic_env/bin/activate  # On Windows: hic_env\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# For GAN architecture
cd GAN
pip install -r requirements.txt
cd ..

# For CLI version
cd HIC-CLI
pip install -r requirements.txt
cd ..
```

### **Dataset Setup**
```bash
# Download hyperspectral datasets from Google Drive
 https://drive.google.com/drive/folders/1cVRjWpbnXWryTWPunhDqZqW_jJaxqS7y?usp=drive_link
#
# Alternatively, datasets are publicly available on Google or you can create
# custom datasets based on your requirements
#
# Place .mat files in respective dataset folders:
# - IndianPines: Indian_pines_corrected.mat, Indian_pines_gt.mat
# - PaviaU: PaviaU.mat, PaviaU_gt.mat
# - Botswana: Botswana.mat, Botswana_gt.mat
# - KSC: KSC.mat, KSC_gt.mat
# - Salinas: Salinas_corrected.mat, Salinas_gt.mat
```

## ğŸ¯ Usage Guide

### **1. Web Interface (Production)**
```bash
# Start the Flask application
python app.py

# Open browser and navigate to
http://localhost:5000

# Features available:
# - User Registration with Face Verification
# - Secure Login with Cryptographic Authentication
# - Model Training Interface
# - Real-time Classification
# - Results Visualization
```

### **2. Command Line Interface (CLI)**
```bash
# Navigate to CLI directory
cd HIC-CLI

# Start a Visdom server for visualization
python -m visdom.server

# Open browser and navigate to
http://localhost:8097  # or http://localhost:9999 if using Docker

# Run the main CLI script
python main.py

# The most useful arguments are:
# --model to specify the model (e.g. 'svm', 'nn', 'HICNN', 'HICAE', 'hamida', 'lee', 'chen', 'li')
# --dataset to specify which dataset to use (e.g. 'PaviaC', 'PaviaU', 'IndianPines', 'KSC', 'Botswana')
# --cuda switch to run the neural nets on GPU. The tool fallbacks on CPU if not specified.

# For more parameters information:
python main.py -h
```

#### **CLI Examples:**
```bash
# Example 1: SVM on Indian Pines dataset
python main.py --model SVM --dataset IndianPines --training_sample 0.3
# This runs a grid search on SVM on the Indian Pines dataset, using 30% of the
# samples for training and the rest for testing. Results are displayed in the visdom panel.

# Example 2: Basic Neural Network on Pavia University
python main.py --model nn --dataset PaviaU --training_sample 0.1 --cuda 0
# This runs on GPU a basic 4-layers fully connected neural network on the Pavia
# University dataset, using 10% of the samples for training.

# Example 3: HICNN on Pavia University
python main.py --model HICNN --dataset PaviaU --training_sample 0.5 --patch_size 7 --epoch 50 --cuda 0
# This runs on GPU the 3D CNN from Hamida et al. on the Pavia University dataset
# with a patch size of 7, using 50% of the samples for training and optimizing for 50 epochs.

# Example 4: HICAE (Autoencoder) model
python main.py --model HICAE --dataset IndianPines --training_sample 0.4 --cuda 0
# This runs the Convolutional Autoencoder model for feature learning and classification.
```

### **3. Training Models**

#### **CNN Architecture (HICNN)**
```bash
# Access training through web interface or direct script
# Select architecture: HICNN
# Choose layers: 3, 5, or 7
# Select optimizer: Adam, SGD, Adadelta, Adagrad
# Set hyperparameters and start training
```

#### **Autoencoder Architecture (HICAE)**
```bash
# Use mlpipeline.py for autoencoder training
# Features: Encoder-Decoder with classification head
# Reconstruction + Classification loss optimization
```

#### **GAN Architecture (HIC-GAN)**
```bash
# Navigate to GAN folder
cd GAN

# Run specific dataset training
jupyter notebook "GAN IndianPines.ipynb"
jupyter notebook "GAN Botswana.ipynb"
jupyter notebook "GAN Salinas.ipynb"

# Monitor training through Excel metrics
# Results saved in Gan Results/ folder
```

### **4. Model Prediction**
```bash
# Web interface prediction
# Upload hyperspectral image â†’ Select model â†’ Get classification

# Direct script usage
python prediction.py --model HICNN --image path/to/hyperspectral.mat
```

## ğŸ”§ Configuration

### **Model Parameters**
```python
# HICNN Configuration
PATCH_SIZE = 5          # Spatial patch size
LEARNING_RATE = 0.01    # Initial learning rate
BATCH_SIZE = 100        # Training batch size
EPOCHS = 200            # Training epochs

# HICAE Configuration
RECONSTRUCTION_WEIGHT = 0.5  # Reconstruction loss weight
CLASSIFICATION_WEIGHT = 0.5  # Classification loss weight

# GAN Configuration
Z_DIM = 100             # Noise vector dimension
H_DIM = 512             # Hidden layer dimension
C_DIM = 16              # Class condition dimension
```

### **Optimizer Settings**
```python
# Available optimizers with typical settings
OPTIMIZERS = {
    'Adam': {'lr': 0.001, 'betas': (0.9, 0.999)},
    'SGD': {'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005},
    'Adadelta': {'lr': 1.0, 'rho': 0.9},
    'Adagrad': {'lr': 0.01, 'weight_decay': 0.01}
}
```
## ğŸ” Security Features

### **Cryptographic Face Verification**
- **Registration**: Secure face template storage with encryption
- **Authentication**: Real-time face verification for login
- **Privacy**: Encrypted .bin files for biometric data protection
- **Anti-spoofing**: Advanced verification algorithms

### **Data Protection**
```python
# Cryptographic implementation highlights
# - AES encryption for biometric templates
# - Secure hash functions for data integrity
# - Protected reference image storage
# - Real-time authentication pipeline
```

## ğŸš€ Deployment

### **Local Deployment**
```bash
# Development server
python app.py

# Production server with Gunicorn
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```

### **Docker Deployment**
```dockerfile
# Dockerfile example
FROM python:3.8-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 5000
CMD ["python", "app.py"]
```

## ğŸ¤ Contributing

### **Development Workflow**
```bash
# Fork the repository
git fork https://github.com/TirumalaManav/HyperspectralNexusMLOps.git

# Create feature branch
git checkout -b feature/new-architecture

# Make changes and commit
git commit -m "Add new hyperspectral architecture"

# Push and create pull request
git push origin feature/new-architecture
```

### **Code Standards**
- **PEP 8**: Python code formatting
- **Type Hints**: Function annotations
- **Documentation**: Comprehensive docstrings
- **Testing**: Unit tests for critical functions


## ğŸ“ˆ Performance Optimization

### **GPU Acceleration**
```python
# CUDA optimization
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Mixed precision training
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()
```

### **Memory Management**
```python
# Efficient data loading
DataLoader(dataset, batch_size=batch_size,
          num_workers=4, pin_memory=True)

# Gradient checkpointing for large models
torch.utils.checkpoint.checkpoint(model_segment, input)
```


## ğŸ› Troubleshooting

### **Common Issues**
```bash
# CUDA out of memory
# Solution: Reduce batch size or use gradient accumulation

# Dataset loading errors
# Solution: Verify .mat file format and path

# Authentication failures
# Solution: Check camera permissions and lighting

# Training instability
# Solution: Adjust learning rate and use gradient clipping
```


## ğŸ“ Support & Contact

### **Primary Authors**
- **Tirumala Manav** (Developer)
  - ğŸ“§ Email: thirumalamanav123@gmail.com
  - ğŸ« Institution: Hyderabad Institute of Technology and Management

- **Bhaskar Das** (Co-Developer)
  - ğŸ« Institution: Hyderabad Institute of Technology and Management

- **Dhananjoy Bhakta** (Co-Developer)
  - ğŸ« Institution: Indian Institute of Information Technology, Ranchi, India

- **Lalan Kumar** (Co-Developer)
  - ğŸ« Institution: Hyderabad Institute of Technology and Management

### **Technical Support**
- ğŸ“‹ **Issues**: GitHub Issues for bug reports
- ğŸ’¬ **Discussions**: GitHub Discussions for questions
- ğŸ“§ **Email**: thirumalamanav123@gmail.com for collaboration
- ğŸŒ **Website**: [Project Documentation](https://github.com/TirumalaManav/HyperspectralNexusMLOps)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
